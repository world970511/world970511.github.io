<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>python 을 이용한 중복 이미지 제거 - 박나은</title>
    <meta name="description" content="회사에서 진행했던 일들 정리(1)">
    <meta property="og:title" content="python 을 이용한 중복 이미지 제거">
    <meta property="og:description" content="회사에서 진행했던 일들 정리(1)">

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="../../images/favicon/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="../../images/favicon/favicon.svg" />
    <link rel="shortcut icon" href="../../images/favicon/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="../../images/favicon/apple-touch-icon.png" />
    <link rel="manifest" href="../../images/favicon/site.webmanifest" />
    
    <link rel="stylesheet" href="../../assets/css/styles.css">
    <link rel="stylesheet" href="../../assets/css/blog-post.css">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
</head>
<body>
    <nav class="nav-container">
        <div class="nav-content">
            <a class="nav-brand" href="../../index.html">박나은</a>
            <div class="nav-tabs">
                <a class="nav-tab" href="../blog-index.html">Blog</a>
            </div>
        </div>
    </nav>
    
    <div class="main-container">
        <article class="blog-post-full">
            <header class="post-header">
                <h1 class="post-title">python 을 이용한 중복 이미지 제거</h1>
                <div class="post-meta">
                    <span>📅 2025년 9월 27일</span>
                    <span>⏱️ 5분 읽기</span>
                    <span>📁 Tech</span>
                </div>
                <div class="post-tags">
                    <span class="post-tag">#python</span><span class="post-tag">#Hash</span><span class="post-tag">#Data processing</span>
                </div>
            </header>
            <div class="post-content">
                <h1 id="회사에서-진행했던-일들-정리1">회사에서 진행했던 일들 정리(1)</h1>
<p>회사에서 정리했던 자료들이 아깝기도하고 해서 블로그로 이전할 겸 적어 본다.<br>아마 나중에도 또 활용할 수도 있겠다 싶은 것도 많아서...<br>이 정도면 크게 문제될 사항은 아닌거 같은 것만 모아 정리할 생각이다.  </p>
<h2 id="🧹-이미지-중복-제거">🧹 이미지 중복 제거</h2>
<p> 데이터를 관리하면서 모델 학습 때마다 다시 데이터셋을 만들어 제공하는 일을 반복하게 되어 중복되는 이미지가 대량으로 발생했다.<br>중복되는 이미지가 있는 데이터셋으로 학습시킬 경우 모델 결과가 떨어지는 문제도 있고, 서버 용량도 문제였기 때문에<br>원할한 데이터 관리를 위해 방법을 찾아야 했다.  </p>
<h3 id="💡-opencv-방식">💡 OpenCV 방식</h3>
<p>초기에는 OpenCV를 사용하여 이미지를 배열로 변환한 뒤, 구조적 유사도를 비교했다.<br>이렇게 구조적 유사도를 사용할 경우 데이터가 많을 수록 속도가 급격히 저하되기 때문에<br>일차적으로 같은 크기를 가진 파일들을 그룹으로 묶고, 그 그룹 안의 이미지를 Array로 전환 후 각각 비교하는 식으로 진행했다.  </p>
<pre><code class="language-python"># 예시
import cv2
import numpy as np

def is_similar_image(img1_path, img2_path, threshold=0.95):
    img1 = cv2.imread(img1_path, 0)
    img2 = cv2.imread(img2_path, 0)
    img1 = cv2.resize(img1, (256, 256))
    img2 = cv2.resize(img2, (256, 256))

    diff = cv2.absdiff(img1, img2)
    similarity = 1 - np.mean(diff) / 255
    return similarity &gt; threshold
</code></pre>
<h4 id="✅-장점">✅ 장점</h4>
<ul>
<li>실제로 <strong>이미지의 구조적 유사성</strong>을 확인할 수 있음 (예: 같은 배경 + 텍스트 다름 등 판단 가능)</li>
</ul>
<h4 id="❌-단점">❌ 단점</h4>
<ul>
<li>비교 대상마다 <strong>이미지를 직접 열고 계산</strong>해야 하므로, <strong>데이터가 많을수록 속도가 급격히 저하</strong></li>
<li>전체 이미지가 수천 장 이상일 경우, 비교 비용은 <code>O(N^2)</code></li>
</ul>
<p>유사도를 중복 제거 시 정확도가 나쁘진 않았으나,<br>단점은 속도였다.<br>당시 거의 10000장 이상의 파일들을 검사해야 했는데 이 방식을 사용하니까 검사하는데 3~4시간 정도는 걸렸던 것 같다.<br>때문에 비동기 처리도 적용해보고 별의별 방법을 써보고 있었는데 그룹장님이 해시를 이용해서 수정하라고 조언해주셔서, 해시를 사용한 중복 제거 방법을 조사했다.</p>
<hr>
<h3 id="💡-해시-기반-방식">💡 해시 기반 방식</h3>
<p>해시로 중복되는 이미지(혹은 파일)을 제거하는 데에는 여러 방법이 있다.</p>
<h5 id="🔹-1-md5--sha-계열-cryptographic-hash">🔹 1. <strong>MD5 / SHA 계열 (Cryptographic Hash)</strong></h5>
<ul>
<li><strong>종류</strong>: <code>MD5</code>, <code>SHA-1</code>, <code>SHA-256</code> 등</li>
<li><strong>원리</strong>: 파일의 바이트(byte) 데이터를 기반으로 고유한 해시값을 생성</li>
<li><strong>특징</strong>:<ul>
<li><strong>완전히 동일한 파일</strong>만 중복으로 인식</li>
<li>이미지 크기나 포맷, 메타데이터가 다르면 <strong>다른 파일로 인식</strong></li>
</ul>
</li>
</ul>
<h5 id="🔹-2-perceptual-hash-phash">🔹 2. <strong>Perceptual Hash (pHash)</strong></h5>
<ul>
<li><strong>원리</strong>: 이미지의 <strong>시각적 특징</strong>을 바탕으로 해시 생성 (보통 DCT 변환 기반)</li>
<li><strong>특징</strong>:<ul>
<li><strong>회전, 크기 변경, 포맷 변경, 밝기 변화</strong>에도 일정 부분 <strong>동일한 해시값 유지</strong></li>
<li>**해시 거리(Hamming distance)**로 유사도 판단 가능</li>
<li><strong>시각적으로 유사한 이미지</strong>도 탐지 가능하지만, 완전히 다른 이미지도 <strong>우연히 비슷한 해시</strong>일 수 있음.</li>
</ul>
</li>
</ul>
<h5 id="🔹-3-average-hash-ahash">🔹 3. <strong>Average Hash (aHash)</strong></h5>
<ul>
<li><strong>원리</strong>: 이미지의 평균 밝기를 기준으로 이진 벡터를 생성</li>
<li><strong>특징</strong>:<ul>
<li>8x8 그레이스케일로 변환 → 각 픽셀이 평균보다 높은지 낮은지 비교</li>
<li>속도가 빠름</li>
<li>간단한 형태 변화에도 어느 정도 유사하게 판단</li>
<li>대비, 패턴에 민감하여 <strong>구분력이 떨어질 수 있음</strong></li>
</ul>
</li>
</ul>
<h5 id="🔹-4-difference-hash-dhash">🔹 4. <strong>Difference Hash (dHash)</strong></h5>
<ul>
<li><strong>원리</strong>: 이미지의 이웃 픽셀 간 밝기 차이를 이용해 해시 생성</li>
<li><strong>특징</strong>:<ul>
<li>픽셀 간 <strong>차이의 방향성</strong>을 반영하기 때문에 구조 변화에 민감</li>
<li>단순 로고/레이아웃 중복 탐지에 유리</li>
<li>밝기, 대비 변화에 약할 수 있음</li>
</ul>
</li>
</ul>
<p>표로 대충 정리하면 밑과 같다  </p>
<table>
<thead>
<tr>
<th>해시 종류</th>
<th>유사 이미지 탐지</th>
<th>속도</th>
<th>정확도</th>
</tr>
</thead>
<tbody><tr>
<td><strong>MD5/SHA</strong></td>
<td>❌ (완전 동일만)</td>
<td>✅ 매우 빠름</td>
<td>✅ 확실함</td>
</tr>
<tr>
<td><strong>pHash</strong></td>
<td>✅ (강력)</td>
<td>⏳ 느림</td>
<td>✅ 매우 우수</td>
</tr>
<tr>
<td><strong>aHash</strong></td>
<td>✅ (보통)</td>
<td>✅ 빠름</td>
<td>⚠️ 약간 부정확</td>
</tr>
<tr>
<td><strong>dHash</strong></td>
<td>✅ (구조에 민감)</td>
<td>✅ 빠름</td>
<td>✅ 구조 강함</td>
</tr>
</tbody></table>
<hr>
<h2 id="🔚-결과">🔚 결과</h2>
<p>일단 가장 급한 문제는 데이터셋을 구축하면서 섞여들어간 복사된 중복 파일들이었기 때문에 MD5를 사용한 중복 파일 제거 스크립트를 구현했다.  </p>
<pre><code class="language-python">import hashlib
from PIL import Image
import io

def calculate_image_hash(image_path):
    with Image.open(image_path) as img:
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format=img.format)
        return hashlib.md5(img_byte_arr.getvalue()).hexdigest()
</code></pre>
<p>전체 코드는 아래와 같은 흐름으로 작동한다.</p>
<ol>
<li>모든 이미지에 대해 해시값을 계산</li>
<li>이미 존재하는 해시값이면 → <strong>중복 이미지로 간주</strong></li>
<li>중복된 이미지는 <code>duplicates</code> 폴더로 이동</li>
</ol>
<p>해시 기반 방식으로 전환 후 5분~10분 내외에 중복 탐지 및 이동까지 완료되면서 나름대로 보람찼었던 기억이 있다.<br>나중엔 이걸 바탕으로 두 폴더를 비교하여 중복 제거하거나 파일 이동 후 복구가 가능하도록 배치 스크립트를 자동으로 짜는 부분을 추가해 복구도 쉽게 처리할 수 있도록 만들었다.</p>
<p>ℹ️ <strong>추가 정보</strong><br>사실 제일 먼저 고려한 건 pHash 였다. 포맷이 다른 중복되는 이미지도 정리하고 싶어서였는데..<br>그냥 문제없어 보이는 파일들도 중복으로 처리 되는 경우가 좀 있어서 추가 검수를 해야 하는 문제가 있었다. 
결국 따로 스크립트를 구현해두는 것으로 완료했다.<br>근데 아무래도 검수를 다시 해야 한다는 부분이 문제라 사용은 한 적이 없다....  </p>

            </div>
            <footer class="post-footer">
                <div class="post-navigation">
                    <a href="../blog-index.html" class="back-to-blog">← 블로그로 돌아가기</a>
                </div>
            </footer>
        </article>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
</body>
</html>